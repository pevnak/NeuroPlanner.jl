<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Usage guide · NeuroPlanner</title><meta name="title" content="Usage guide · NeuroPlanner"/><meta property="og:title" content="Usage guide · NeuroPlanner"/><meta property="twitter:title" content="Usage guide · NeuroPlanner"/><meta name="description" content="Documentation for NeuroPlanner."/><meta property="og:description" content="Documentation for NeuroPlanner."/><meta property="twitter:description" content="Documentation for NeuroPlanner."/><meta property="og:url" content="https://Pevnak.github.io/NeuroPlanner/usage_guide/"/><meta property="twitter:url" content="https://Pevnak.github.io/NeuroPlanner/usage_guide/"/><link rel="canonical" href="https://Pevnak.github.io/NeuroPlanner/usage_guide/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/favicon.ico" rel="icon" type="image/x-icon"/><link href="../assets/onlinestats.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">NeuroPlanner</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../heuristic/">Heuristic</a></li><li class="is-active"><a class="tocitem" href>Usage guide</a><ul class="internal"><li><a class="tocitem" href="#Model-creation"><span>Model creation</span></a></li><li><a class="tocitem" href="#Model-training"><span>Model training</span></a></li><li><a class="tocitem" href="#Model-usage"><span>Model usage</span></a></li></ul></li><li><a class="tocitem" href="../theory/">Theoretical background</a></li><li><a class="tocitem" href="../losses/">Losses</a></li><li><a class="tocitem" href="../extractors/">Extractors</a></li><li><a class="tocitem" href="../model_representation/">Model representation</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Usage guide</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Usage guide</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/Pevnak/NeuroPlanner.jl/blob/main/docs/src/usage_guide.md#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Usage-guide"><a class="docs-heading-anchor" href="#Usage-guide">Usage guide</a><a id="Usage-guide-1"></a><a class="docs-heading-anchor-permalink" href="#Usage-guide" title="Permalink"></a></h1><p>The Neuroplanner library allows for creation and training of a heuristic function to use in planning problems. This function is represented by a neural network model; therfore, for it to be ready for use, several steps must be completed.</p><hr/><h2 id="Model-creation"><a class="docs-heading-anchor" href="#Model-creation">Model creation</a><a id="Model-creation-1"></a><a class="docs-heading-anchor-permalink" href="#Model-creation" title="Permalink"></a></h2><p>To begin, necessarry libraries are imported.</p><pre><code class="language-julia hljs">using NeuroPlanner
using NeuroPlanner.PDDL
using NeuroPlanner.Flux
using NeuroPlanner.SymbolicPlanners
using PDDL: GenericProblem
using NeuroPlanner.SymbolicPlanners: PathSearchSolution
using Statistics
using Random
using Accessors
using NeuroPlanner.Mill</code></pre><p>Then a representation of the domain we will be working with is needed. PDDL has a helper function load_domain() into which the string path locationof domain.pddl file to be loaded is passed. </p><pre><code class="language-julia hljs">domain = load_domain(&quot;../domains/ferry/domain.pddl&quot;)</code></pre><p>Is also helpful to keep the string paths to the problem files we will be dealing with. They can be loaded for example as such:</p><pre><code class="language-julia hljs">problem_files = [joinpath(&quot;../domains/ferry/&quot;, f) for f in readdir(&quot;../domains/ferry&quot;) if endswith(f,&quot;.pddl&quot;) &amp;&amp; f !== &quot;domain.pddl&quot;]</code></pre><hr/><p>Problems from the domain require an extractor (here called <code>pddld</code>) to be parsed in a standardised form. When creating an extractor we can choose from diferrent architectures (<code>ASNet</code>, <code>HyperExtractor</code>, <code>HGNNLite</code>, <code>HGNN</code>, <code>LevinASNet</code>), which fundamentally change how the problem, and as a result the model, are internally represented and will affect how the final heuristic behaves. Details here: <a href="../extractors/">Extractors</a>, <a href="../theory/">Theoretical background</a>.</p><pre><code class="language-julia hljs">pddld = ASNet(domain)
pddld = HGNNLite(domain)
pddld = HGNN(domain)
pddld = ObjectBinary(domain)
pddld = AtomBinary(domain)
pddld = ObjectAtom(domain)
pddld = ObjectAtomBip(domain)
pddld = LevinASNet(domain)</code></pre><p>Note that the last <code>LevinASNet</code> is a version of <code>ASNet</code> adapted to be used with the <code>LevinLoss</code> and <code>LevinAStar</code> to implement the method from the paper</p><p>Now the chosen extractor has to be specialized for a given problem instance. First a problem is loaded with the <code>load_problem()</code> function (any problem from the set will do, we are choosing the first one for simplicity). Next <code>specialize()</code> is used to create the specialized extractor <code>pddle</code>, and create the initial state of the problem with <code>initstate(domain, problem)</code></p><pre><code class="language-julia hljs">problem = load_problem(first(problem_files))
pddle = specialize(pddld, problem)
state = initstate(domain, problem)</code></pre><p>Alternatively both specialization of the extractor and creation of the inital state can be done by calling <code>initproblem()</code></p><pre><code class="language-julia hljs">pddle, state = initproblem(pddld, problem)</code></pre><p>To use the specialized extractor, its functor is called on the state to be extracted. The inital state is extracted so the model can be created from it later.</p><pre><code class="language-julia hljs">h₀ = pddle(state)</code></pre><hr/><p>With the extracted state the model is created with the Mill.jl <code>reflectinmodel()</code> function. This is an example of how the model creation can look. Brief explanation of the args used here:</p><p><code>h₀</code> A state that the model will be able to process, specifies structure of the model.</p><p><code>d -&gt; Dense(d, dense_dim, relu)</code> Setting of dense layers, output will be = dense_dim, activation function is relu.</p><p><code>fsm = Dict(&quot;&quot; =&gt;  d -&gt; ffnn(d, dense_dim, 1, dense_layers))</code> optional kwarg, overrides constructions of feed-forward models. Here <code>&quot;&quot;</code> in fsm denotes the last (output) layer, so these are settings for the last layer. (The 1 is the output dimension)</p><pre><code class="language-julia hljs">model = reflectinmodel(h₀, d -&gt; Dense(d, 32, relu);fsm = Dict(&quot;&quot; =&gt;  d -&gt; Chain(Dense(d,32,relu), Dense(32,1))))</code></pre><p>For more optional keyword arguments and info on this function see <a href="https://ctuavastlab.github.io/Mill.jl/stable/manual/reflectin/">Mill.jl documentation on the topic</a>.</p><hr/><h2 id="Model-training"><a class="docs-heading-anchor" href="#Model-training">Model training</a><a id="Model-training-1"></a><a class="docs-heading-anchor-permalink" href="#Model-training" title="Permalink"></a></h2><p>To make training efficient the data is split into minibatches. In NeuroPlanner minibatches are tied one-to-one with loss functions; each loss function has a minibatch constructor that prepares the data in a way that the loss function can parse. Options for loss functions are: <code>l2</code>, <code>l₂</code>, <code>lstar</code>, <code>lₛ</code>, <code>lgbfs</code>, <code>lrt</code>, <code>bellman</code>, <code>levinloss</code>. With any of these the constructor can be created. For info on differences in loss functions see <a href="../losses/">Losses</a>, or the <a href="../theory/">Theoretical background</a>.</p><pre><code class="language-julia hljs">fminibatch = NeuroPlanner.minibatchconstructor(&quot;l2&quot;) 
fminibatch = NeuroPlanner.minibatchconstructor(&quot;l₂&quot;) 
fminibatch = NeuroPlanner.minibatchconstructor(&quot;lstar&quot;) 
fminibatch = NeuroPlanner.minibatchconstructor(&quot;lₛ&quot;) 
fminibatch = NeuroPlanner.minibatchconstructor(&quot;lgbfs&quot;) 
fminibatch = NeuroPlanner.minibatchconstructor(&quot;lrt&quot;) 
fminibatch = NeuroPlanner.minibatchconstructor(&quot;bellman&quot;) 
fminibatch = NeuroPlanner.minibatchconstructor(&quot;levinloss&quot;) </code></pre><p>With the constructor made, the batches can be created with the code snippet below. Deduplicate is a Neuroplanner function which eliminates redudant data from the batches, cutting down the size dramatically.</p><pre><code class="language-julia hljs">train_files = filter(isfile ∘ NeuroPlanner.plan_file, problem_files)
minibatches = map(train_files) do problem_file
			  plan = load_plan(problem_file)
		 	  problem = load_problem(problem_file)
			  ds = fminibatch(pddld, domain, problem, plan)
			  dedu = @set ds.x = deduplicate(ds.x)
			  end</code></pre><p>An <a href="https://fluxml.ai/Optimisers.jl/dev/api/#Optimisation-Rules">optimiser</a> is chosen (any works, for brevity <code>AdaBelief()</code> is picked here) and model parameters are extracted.</p><pre><code class="language-julia hljs">using Flux.Optimisers
opt_state = Optimisers.setup(Optimisers.AdaBelief(), model) </code></pre><hr/><p>The model is trained with <code>train!()</code>. </p><p><code>NeuroPlanner.loss</code> passes the generic NeuroPlanner loss, which will dispatch to the correct loss based on the minibatch passed to it.</p><p><code>model,opt_state</code> are the pre-prepared structs.  </p><pre><code class="language-julia hljs">for i in 1:10_000
	mb = rand(minibatches)
	l, ∇model = Flux.withgradient(model -&gt; NeuroPlanner.loss(model, mb), model)
	state_tree, model = Optimisers.update(state_tree, model, ∇model[1]);
end</code></pre><p>With this the model is trained and ready to be used.</p><hr/><h2 id="Model-usage"><a class="docs-heading-anchor" href="#Model-usage">Model usage</a><a id="Model-usage-1"></a><a class="docs-heading-anchor-permalink" href="#Model-usage" title="Permalink"></a></h2><p>The simplest way of using the trained model is to call its functor. It computes the value of the heuristic function for the extracted state passed to it.</p><pre><code class="language-julia hljs">heur_value = model(pddle(state))</code></pre><p>This, however, can be slow and unwieldy to work with at a large scale. NeuroPlanner provides several helper functions to make working with a trained model easier.</p><p><code>solve_problem()</code> solves the problem in the problem_files, using the passed model, extractor and planner. It returns a solution object, which has fields describing details of how the problem was solved.</p><pre><code class="language-julia hljs">sol = solve_problem(pddld, problem_file, model, planner; return_unsolved = true)</code></pre><p>If we want to compare to a non-heuristic solution, the <code>solveproblem()</code> solves the problem using a standard forward planner with a null heuristic. It only takes the domain of the problem and the problem file`` as the input.</p><pre><code class="language-julia hljs">sol = solveproblem(domain, problem_file)</code></pre><p>It is also an option to create a <code>NeuroHeuristic()</code> which behaves like a normal heuristic object and can be passed to constructors of planners.</p><pre><code class="language-julia hljs">hfun = NeuroHeuristic(pddld, problem, model)
planner = AStarPlanner(hfun)</code></pre><p>The planners availiable are [<code>AStarPlanner</code>, <code>GreedyPlanner</code>, <code>W15AStarPlanner</code>, <code>W20AStarPlanner</code>] and <code>BFSPlanner</code> which is used with the LevinAsnet model. Once created, the planner can be used to also get the solution of a given problem.</p><pre><code class="language-julia hljs">sol = planner(domain, state₀, PDDL.get_goal(problem))</code></pre><p>To quickly display a collection of solutions, the <code>show_stats</code> which prints relevant data to console.</p><pre><code class="language-julia hljs">show_stats(solutions)</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../heuristic/">« Heuristic</a><a class="docs-footer-nextpage" href="../theory/">Theoretical background »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.4.1 on <span class="colophon-date" title="Tuesday 11 June 2024 08:29">Tuesday 11 June 2024</span>. Using Julia version 1.10.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
