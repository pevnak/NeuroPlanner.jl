using SymbolicPlanners: PathNode
const SearchTree = Dict{UInt64, PathNode{GenericState}}

"""
(trajectory, plan) = sample_backward_trace(domain, problem, depth; full_states = true, remove_cycles = true)
(trajectory, plan) = sample_backward_trace(domain, problem, goal_state, depth; full_states = true, remove_cycles = true)

random trace ending in `goal_state = goalstate(domain, problem)` generated by 
`regress`ing the goal_state

full_states --- returned trajectory is replayed by `simulate(StateRecorder(), domain, state, plan)` returning more
			complete states then partial states 
remove_cycles --- remove cycles from the trajectory (and plan)
"""
function sample_backward_trace(domain, problem, depth; full_states = true, remove_cycles = true)
	sample_backward_trace(domain, problem, goalstate(domain, problem), depth; full_states, remove_cycles)
end

function sample_backward_trace(domain, problem, goal_state, depth; full_states = true, remove_cycles = true)
	state = goal_state
	plan = []
	trajectory = [state]
	for i in 1:depth
		acts = relevant(domain, state)
		isempty(acts) && break 
		act = rand(acts)
		next_state = regress(domain, state, act; check=false)
		push!(trajectory, next_state)
		push!(plan, act)
		state = next_state
	end
	trajectory, plan = reverse(trajectory), reverse(plan)
	if full_states
		trajectory = SymbolicPlanners.simulate(StateRecorder(), domain, state, plan)
	end
	if remove_cycles
		trajectory, plan =  removecycles(trajectory, plan)
	end
	!issubset(goal_state, last(trajectory)) && error("Something went terribly wrong, goal_state is not last in trajectory. File an issue.")
	return(trajectory, plan)
end

"""
execute_backward_plan(domain, problem, goal_state, plan; full_states = true)
execute_backward_plan(domain, problem, plan; full_states = true)

return a trajectory of a plan executed from the goal state forward. The plan should be already
reversed.
"""
function execute_backward_plan(domain, problem, goal_state, plan; full_states = true)
	state = goal_state
	trajectory = [state]
	for act in plan
		acts = relevant(domain, state)
		isempty(acts) && error("No action exist even though the plan has actions left")
		act ∉ acts  && error("empty intersection of actions and action from the plan")
		next_state = regress(domain, state, act; check=false)
		push!(trajectory, next_state)
		state = next_state
	end
	trajectory, plan = reverse(trajectory), reverse(plan)
	if full_states
		trajectory = SymbolicPlanners.simulate(StateRecorder(), domain, state, plan)
	end
	!issubset(goal_state, last(trajectory)) && error("Something went terribly wrong, goal_state is not last in trajectory. File an issue.")
	return(trajectory, plan)	
end

function execute_backward_plan(domain, problem, plan; full_states = true)
	execute_backward_plan(domain, problem, goalstate(domain, problem), plan; full_states)
end

"""
search_tree = sample_backward_tree(domain, problem; max_depth = 30, max_leaves=10_000, max_states=100_000)
search_tree = sample_backward_tree(domain, problem, goal_state; max_depth = 30, max_leaves=10_000, max_states=100_000)

random search_tree of backward search, which means that the root node ends 
in `goal_state = goalstate(domain, problem).` Tree is generated by 
`regress`ing the state. Cycles are not detected. 

max_depth --- maximum depth of the node to be expanded
max_leaves --- maximum number of states in the open set (corrends to leafs)
max_states --- maximum number of states in the search tree
"""
function sample_backward_tree(domain, problem; max_depth = 30, max_states=100_000)
	goal_state =  goalstate(domain, problem)
	sample_backward_tree(domain, problem, goal_state;max_depth, max_states)
end

function sample_backward_tree(domain, problem, goal_state; max_depth = 30, max_states=100_000)
	state = goal_state
	node_id = hash(state)
	search_tree = Dict(node_id => PathNode(node_id, state, 0.0))
	open_states = Set([node_id])
	expanded_states = 0
	while !isempty(open_states)
		node_id = rand(open_states)
		pop!(open_states, node_id)
		state = search_tree[node_id].state
		g = search_tree[node_id].path_cost
		acts = relevant(domain, state)
		expanded_states += 1
		for act in acts
			next_state = regress(domain, state, act; check=false)
			next_id = hash(next_state)
			next_id ∈ keys(search_tree) && continue
			search_tree[next_id] = PathNode(next_id, next_state, g + 1, node_id, act)
			push!(open_states, next_id)
		end
		length(search_tree) ≥ max_states && break
	end
	println("open states: ",length(open_states), " search tree: ", length(search_tree), " expanded states: ",expanded_states," max depth: ",maximum(s.path_cost for s in values(search_tree)))
	search_tree
end

function sample_backward_trace(domain, search_tree::Dict; full_states = true, sample_goal = false)
	sample_backward_trace(search_tree, leafs(search_tree); full_states, sample_goal)
end

function sample_backward_trace(domain, search_tree::Dict, l; full_states = true, sample_goal = false)
	id = rand(l)
	trajectory =  Vector{GenericState}()
	plan =  []
	while(true)
		v = search_tree[id]
		push!(trajectory, v.state)
		v.parent_id === nothing && break
		push!(plan, v.parent_action)
		id = v.parent_id
	end
	if full_states
		state = first(trajectory)
		trajectory = SymbolicPlanners.simulate(StateRecorder(), domain, state, plan)
	end
	if sample_goal && length(trajectory) > 2 
		i = rand(2:length(trajectory))
		trajectory = trajectory[1:i]
		plan = plan[1:i-1]
	end
	trajectory, plan
end


"""
struct BackwardSampler{D,S<:Dict,L,F}
	domain::D
	search_tree::S
	l::L
	full_states::Bool
	sample_goal::Bool
	fminibatch::F
end

Simplify sampling a random solution from a tree and then creating minibatch from it.
It wraps all arguments of the sampler and the run it. 
"""
struct BackwardSampler{D,P,S<:Dict,L}
	domain::D
	problem::P
	search_tree::S
	l::L
	full_states::Bool
	sample_goal::Bool
end

function BackwardSampler(domain, problem::GenericProblem; full_states = true, sample_goal = false, max_states = 100_000, max_depth = 30)
	search_tree = sample_backward_tree(domain, problem; max_depth, max_states)
	l = leafs(search_tree)
	BackwardSampler(domain, problem, search_tree, l, full_states, sample_goal)
end

function Base.show(io::IO, bs::BackwardSampler)
	println(io, "BackwardSampler (treesize: ", length(bs.search_tree), ", leafs: ", length(bs.l), ", full states: ", bs.full_states, ", sample goal:", bs.sample_goal,")")
end

function (bs::BackwardSampler)(;full_states = bs.full_states, sample_goal = bs.sample_goal)
	sample_backward_trace(bs.domain, bs.search_tree, bs.l;full_states, sample_goal)
end


"""
(trajectory, plan) = sample_forward_trace(domain, problem, depth; full_states = true, remove_cycles = true)
(trajectory, plan) = sample_forward_trace(domain, problem, initial_state, depth; full_states = true, remove_cycles = true)

random trace starting in `initial_state = initstate(domain, problem)` generated by 
expanding the initial state

full_states --- returned trajectory is replayed by `simulate(StateRecorder(), domain, state, plan)` returning more
			complete states then partial states 
remove_cycles --- remove cycles from the trajectory (and plan)
"""
function sample_forward_trace(domain, problem, depth; remove_cycles = true)
	sample_forward_trace(domain, problem, initstate(domain, problem), depth; remove_cycles)
end

function sample_forward_trace(domain, problem, initial_state, depth; remove_cycles = true)
	state = initial_state
	plan = []
	trajectory = [state]
	for i in 1:depth
		acts = available(domain, state)
		isempty(acts) && break 
		act = rand(acts)
		next_state = execute(domain, state, act; check=false)
		push!(trajectory, next_state)
		push!(plan, act)
		state = next_state
	end
	if remove_cycles
		trajectory, plan =  removecycles(trajectory, plan)
	end
	return(trajectory, plan)
end


"""
search_tree_from_trajectory(domain, trajectory, plan)

expand states off the trajectory to create search tree returned by 
an optimal search expanding only states on the trajectory. 
"""
function search_tree_from_trajectory(domain, trajectory, plan)
	state = first(trajectory)

	node_id = hash(state)
	search_tree = Dict(node_id => PathNode(node_id, state, 0))
	for (i, state) in enumerate(trajectory[1:end-1])
		add_descendants!(search_tree, domain, state, i - 1)
	end
	@assert all(haskey(search_tree, hash(s)) for s in trajectory)
	search_tree
end

function add_descendants!(search_tree::SearchTree, domain, state, g)
	parent_id = hash(state)
    for act in available(domain, state)
        next_state = execute(domain, state, act; check=false)
        node_id = hash(next_state)
        get!(search_tree, node_id, PathNode(node_id, next_state, g+1, parent_id, act))
    end
    search_tree
end

"""
(trajectory, plan) = removecycles(trajectory, plan)

detect cycle in trajectory and truncate it (together with plan), 
such that the cycle is removed.
"""
function removecycles(trajectory, plan)
	j = firstcycle(trajectory)
	j == nothing && return(trajectory, plan)
	@assert j < length(trajectory)
	j = j + 1
	trajectory[j:end], plan[j:end]
end

function firstcycle(trajectory)
	cycles = Int[]
	for i in eachindex(trajectory)
		for j in i+1:lastindex(trajectory)
			trajectory[i] == trajectory[j] && push!(cycles, i)
		end 
	end
	isempty(cycles) && return(nothing)
	return(maximum(cycles))
end

"""
	plan_from_trajectory(domain, problem, trajectory)

	extract the plan from a trajectory

"""
function plan_from_trajectory(domain, problem, trajectory)
	state = initstate(domain, problem)
	goal = goalstate(domain, problem)
	!issubset(state.facts, trajectory[1].facts) && error("initial state not in the trajectory")
	!issubset(goal.facts, trajectory[end].facts) && error("goal state not in the trajectory")
	plan = map(zip(trajectory[1:end-1], trajectory[2:end])) do (s, t)
		acts = filter(available(domain, s)) do act
			u = execute(domain, s, act; check=false)
			issubset(t,u)
		end
		isempty(acts) && error("actions are empty")
		first(acts)
	end
	plan
end

"""
	verify_plan(domain, problem, plan)

	verify the plan is solving the problem

"""
function verify_plan(domain, problem, plan)
	trajectory = SymbolicPlanners.simulate(StateRecorder(), domain, initstate(domain, problem), plan)
	gstate = goalstate(domain, problem)
	issubset(gstate.facts, trajectory[end].facts)
end


